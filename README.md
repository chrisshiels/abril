# abril

## Overview

Explore building a docker based infrastructure supporting blue / green
deployments of pools of semantic versioned microservices:

- Here we can start multiple containers of the web microservice and it's
  dependency microservices date and time.

- The web microservice containers can discover their dependencies via DNS
  queries for the *service consumer endpoints* date-1.service.consul and
  time-1.service.consul.

- All microservice containers are registered at DNS SRV *service implementation
  endpoints* 1.0.0.date.service.consul, 1.0.1.date.service.consul, etc.

- The *service consumer endpoints* are DNS CNAME aliases for the current
  live *service implementation endpoints* and these can be repointed to
  new versions after smoke testing, etc.


Technologies used are Golang, Docker Engine, Consul, Registrator,
Consul-template, HAProxy, Swarm, Docker-compose, Vagrant and libvirt:

- The date, time and web microservices are all coded in Golang.

- Newly started containers are discovered by Registrator and registered
  in Consul which then handles DNS queries for the .consul domain.

- HAProxy configuration is generated by Consul-template querying the
  Registrator populated records from Consul.

- Docker-compose is used to start and stop pools of microservice containers
  via Swarm which in turn uses Consul as its discovery backend.

- This environment was constructed using Vagrant / libvirt-based virtual
  machines running CentOS 7.

Note that these notes are a work in progress generated during exploring
these technologies - everything here works but more work is required.


## Scenario

Test environment is as follows:
```
rothko$ cat /etc/redhat-release
CentOS Linux release 7.2.1511 (Core)

rothko$ grep vmx /proc/cpuinfo | wc -l
4

rothko$ free -m
              total        used        free      shared  buff/cache   available
Mem:           7732        1399        4902         455        1430        5564
Swap:          8187           0        8187

rothko$ rpm -q vagrant
vagrant-1.8.1-1.x86_64
```


## Preparation - Rpms

Build rpms for consul, consul-template, docker-compose, golang-1.6.2 and
registrator.

First download sources:
```
rothko$ cd ~/abril/rpmbuild/centos/7/x86_64/SOURCES
rothko$ make
```


Then build:
```
rothko$ sudo docker run -i -t --rm \
	-v /home/chris:/home/chris \
	centos:7 /bin/bash
9dab13a3f022# /usr/sbin/groupadd -g 1000 chris
9dab13a3f022# /usr/sbin/useradd \
	-u 1000 -g 1000 -c 'Chris Shiels' -d /home/chris -s /bin/bash -M chris
9dab13a3f022# gpasswd -a chris wheel
9dab13a3f022# yum -y install sudo
9dab13a3f022# echo '%wheel ALL=(ALL) NOPASSWD: ALL' > /etc/sudoers.d/wheel
9dab13a3f022# chmod 440 /etc/sudoers.d/wheel
9dab13a3f022# /usr/sbin/visudo -c
9dab13a3f022# exec /bin/su - chris

9dab13a3f022$ cd /home/chris/abril/rpmbuild/centos/7/x86_64/
9dab13a3f022$ ./setup.sh
9dab13a3f022$ sudo yum -y install rpm-build make libpcap-devel git golang
9dab13a3f022$ sudo yum -y install https://dl.iuscommunity.org/pub/ius/stable/CentOS/7/x86_64/ius-release-1.0-14.ius.centos7.noarch.rpm
9dab13a3f022$ sudo yum -y install python35u

9dab13a3f022$ for f in SPECS/*.spec
do
	rpmbuild -ba $f || break
done
9dab13a3f022$ exit
```


## Preparation - Workstation network manager / dnsmasq

I want all http requests from the host for the .abril domain to be handled
by the HAProxy servers and given my CentOS 7 laptop is running
NetworkManager I'm leveraging this to start up a dnsmasq process to handle
dns queries for the .abril domain.
```
rothko$ sudo tee /etc/NetworkManager/conf.d/abril.conf <<eof
[main]
dhcp=dhclient
dns=dnsmasq
eof

rothko$ sudo tee /etc/NetworkManager/dnsmasq.d/abril.conf <<eof
address=/.abril/192.168.40.13
host-record=vm1,192.168.40.11
host-record=vm2,192.168.40.12
host-record=vm3,192.168.40.13
eof

rothko$ sudo /bin/systemctl restart NetworkManager.service
rothko$ sudo /bin/systemctl status NetworkManager.service
```


Check:
```
rothko$ cat /var/run/NetworkManager/dnsmasq.conf
server=192.168.33.200

rothko$ cat /etc/resolv.conf
# Generated by NetworkManager
search home.mecachis.net
nameserver 127.0.0.1

rothko$ dig +short hello.abril
192.168.40.13
rothko$ dig +short vm1
192.168.40.11
rothko$ dig +short vm2
192.168.40.12
rothko$ dig +short vm3
192.168.40.13
```


## Preparation - Workstation iptables

Needed to support Vagrant synced folders via nfs:
```
rothko$ sudo /sbin/iptables -I INPUT 1 -i virbr+ -j ACCEPT
```


## Virtual machines

Use Vagrant to start 3 libvirt-based virtual machines vm1, vm2 and vm3
running on fixed IP addresses 192.168.40.11, 192.168.40.12 and
 192.168.40.13.

The Vagrantfile configures nfs-based synced folders and also configures
 hostnames, timezone, rsyslog and install Docker Engine.
```
rothko$ cd ~/abril
rothko$ vagrant up
```


Open three different terminal windows and in each connect to the virtual
machines.
```
rothko$ vagrant ssh vm1
rothko$ vagrant ssh vm2
rothko$ vagrant ssh vm3
```


From this point onwards in the notes a shell prompt of vm123$ indicates
a command to be run on all of the virtual machines and a shell prompt
of, e.g., vm1 indicates a command to be run on vm1 only.


## Network manager / dnsmasq

Configure virtual machines' local dns to forward all queries for the
.consul domain to the local Consul server.

Leveraging already running NetworkManager to configure a
NetworkManager-managed dnsmasq process to handle this.

In order that dns resolves correctly within the containers, the
below configuration sets the contents of /etc/resolv.conf to
point at the vm's eth0 address, and not the default 127.0.0.1, and enables
listening on eth0.
```
vm123$ sudo tee /etc/NetworkManager/conf.d/abril.conf <<'eof'
[main]
dhcp=dhclient
dns=dnsmasq
eof

vm123$ sudo tee /etc/NetworkManager/dnsmasq.d/abril.conf <<'eof'
server=/consul/127.0.0.1#8600
interface=eth0
eof

vm123$ sudo tee /etc/NetworkManager/dispatcher.d/abril <<'eof'
#!/bin/bash

[ "$1" = "eth0" -a "$2" = "up" ] || exit

echo "nameserver $DHCP4_IP_ADDRESS" > /etc/resolv.conf
eof
vm123$ sudo chmod 755 /etc/NetworkManager/dispatcher.d/abril

vm123$ sudo /bin/systemctl restart NetworkManager.service
vm123$ sudo /bin/systemctl status NetworkManager.service
```


Check:
```
vm1$ cat /var/run/NetworkManager/dnsmasq.conf
server=192.168.121.1

vm1$ cat /etc/resolv.conf
nameserver 192.168.121.163
```


## Consul

Setup Consul.
```
vm123$ sudo yum -y localinstall /vagrant/rpmbuild/centos/7/x86_64/RPMS/x86_64/consul-0.6.4-1.mecachis.centos7.x86_64.rpm

vm1$ sudo tee /etc/sysconfig/consul <<eof
OPTIONS="-server -data-dir /usr/local/var/lib/consul -bootstrap-expect 3 -bind 192.168.40.11 -retry-join 192.168.40.12 -retry-join 192.168.40.13"
eof

vm2$ sudo tee /etc/sysconfig/consul <<eof
OPTIONS="-server -data-dir /usr/local/var/lib/consul -bootstrap-expect 3 -bind 192.168.40.12 -retry-join 192.168.40.11 -retry-join 192.168.40.13"
eof

vm3$ sudo tee /etc/sysconfig/consul <<eof
OPTIONS="-server -data-dir /usr/local/var/lib/consul -bootstrap-expect 3 -bind 192.168.40.13 -retry-join 192.168.40.11 -retry-join 192.168.40.12"
eof

vm123$ sudo tee /usr/local/etc/consul/conf.d/config.json <<eof
{
  "disable_update_check": true,
  "leave_on_terminate": false,
  "skip_leave_on_interrupt": true,
  "domain": "consul",
  "client_addr": "0.0.0.0"
}
eof

vm123$ sudo /bin/systemctl enable consul.service
vm123$ sudo /bin/systemctl start consul.service
vm123$ sudo /bin/systemctl status consul.service
```


Check:
```
vm123$ curl -s http://localhost:8500/v1/status/leader | python -mjson.tool
vm123$ curl -s http://localhost:8500/v1/status/peers | python -mjson.tool
vm123$ curl -s http://localhost:8500/v1/catalog/services | python -m json.tool
vm123$ curl -s http://localhost:8500/v1/catalog/nodes | python -m json.tool
vm123$ curl -s http://localhost:8500/v1/kv/?recurse | python -mjson.tool
vm123$ sudo yum -y install bind-utils
vm123$ dig +short vm1.node.dc1.consul
vm123$ dig +short www.microsoft.com
```


## Docker remote access

Configure Docker Engine remote access.
```
vm123$ sudo mkdir /etc/systemd/system/docker.service.d
vm123$ sudo tee /etc/systemd/system/docker.service.d/sysconfig.conf <<'eof'
[Service]
EnvironmentFile=/etc/sysconfig/docker
ExecStart=
ExecStart=/usr/bin/docker daemon $OPTIONS
eof

vm123$ sudo tee /etc/sysconfig/docker <<eof
OPTIONS="-H fd:// -H tcp://0.0.0.0:2375"
eof

vm123$ sudo /bin/systemctl reenable docker.service
vm123$ sudo /bin/systemctl restart docker.service
vm123$ sudo /bin/systemctl status docker.service
```


Check:
```
vm123$ ps auxww | grep -- -H
vm123$ sudo docker -H tcp://127.0.0.1:2375/ ps -a
```


## Docker registry certs
```
vm1$ cd /vagrant/ssl
vm1$ make

vm123$ sudo mkdir -p /etc/docker/certs.d/registry.service.consul:5000
vm123$ sudo cp \
	/vagrant/ssl/registry.service.consul.crt \
	/etc/docker/certs.d/registry.service.consul:5000/ca.crt
vm123$ sudo /usr/bin/systemctl restart docker.service
vm123$ sudo /usr/bin/systemctl status docker.service
```


## Swarm

Note we can't specify consul://localhost:8500/swarm here as localhost isn't
what you think it is - here it's localhost **inside** the container...
```
vm1$ sudo docker run -d --restart=unless-stopped \
	swarm:1.2.2 join \
		--advertise 192.168.40.11:2375 \
		consul://192.168.40.11:8500/swarm

vm2$ sudo docker run -d --restart=unless-stopped \
	swarm:1.2.2 join \
		--advertise 192.168.40.12:2375 \
		consul://192.168.40.12:8500/swarm

vm3$ sudo docker run -d --restart=unless-stopped \
	swarm:1.2.2 join \
		--advertise 192.168.40.13:2375 \
		consul://192.168.40.13:8500/swarm

vm1$ sudo docker run -d --restart=unless-stopped -p 3375:3375 \
	swarm:1.2.2 manage \
		-H 0.0.0.0:3375 \
		--replication \
		--advertise 192.168.40.11:3375 \
		consul://192.168.40.11:8500/swarm

vm2$ sudo docker run -d --restart=unless-stopped -p 3375:3375 \
	swarm:1.2.2 manage \
		-H 0.0.0.0:3375 \
		--replication \
		--advertise 192.168.40.12:3375 \
		consul://192.168.40.11:8500/swarm

vm3$ sudo docker run -d --restart=unless-stopped -p 3375:3375 \
	swarm:1.2.2 manage \
		-H 0.0.0.0:3375 \
		--replication \
		--advertise 192.168.40.13:3375 \
		consul://192.168.40.11:8500/swarm

vm1$ sudo docker run --rm \
	swarm:1.2.2 list \
		consul://192.168.40.11:8500/swarm
```


Check:
```
vm1$ curl -s http://localhost:8500/v1/kv/swarm?recurse | python -mjson.tool
vm1$ docker -H tcp://vm1:3375/ info
vm1$ docker -H tcp://vm2:3375/ info
vm1$ docker -H tcp://vm3:3375/ info
vm1$ docker -H tcp://vm1:3375/ ps -a
vm1$ docker -H tcp://vm2:3375/ ps -a
vm1$ docker -H tcp://vm3:3375/ ps -a
```


## Registry
```
vm1$ sudo yum -y install https://dl.iuscommunity.org/pub/ius/stable/CentOS/7/x86_64/ius-release-1.0-14.ius.centos7.noarch.rpm
vm1$ sudo yum -y install python35u
vm1$ sudo yum -y localinstall /vagrant/rpmbuild/centos/7/x86_64/RPMS/x86_64/docker-compose-1.7.0-1.mecachis.centos7.x86_64.rpm

vm1$ cd /vagrant/dockercompose/registry/
vm1$ cat docker-compose.yml
---

# 'docker-compose.yml'.


version: '2'


services:
  registry:
    hostname: registry
    image: registry:2
    restart: unless-stopped
    network_mode: bridge
    ports:
    - '5000:5000'
    volumes:
    - /vagrant/ssl:/certs
    - /home/vagrant/registry:/var/lib/registry
    environment:
    - REGISTRY_HTTP_TLS_CERTIFICATE=/certs/registry.service.consul.crt
    - REGISTRY_HTTP_TLS_KEY=/certs/registry.service.consul.key
    - 'constraint:node==vm1'
    labels:
    - SERVICE_NAME=registry

vm1$ /usr/local/docker-compose/bin/docker-compose -H tcp://vm1:3375 up -d
```

Note this will fail with '404 page not found' if you specify
a trailing slash to the -H argument, e.g. -H tcp://vm1:3375/


Check:
```
vm1$ docker -H tcp://vm1:3375/ logs -f registry_registry_1
^c

vm1$ /usr/local/docker-compose/bin/docker-compose -H tcp://vm1:3375 ps
vm1$ docker -H tcp://vm1:3375/ ps
```


## Registrator
```
vm123$ sudo yum -y localinstall /vagrant/rpmbuild/centos/7/x86_64/RPMS/x86_64/registrator-20160427-1.mecachis.centos7.x86_64.rpm

vm123$ cat /etc/sysconfig/registrator
OPTIONS="-cleanup consul://localhost:8500"

vm123$ sudo /bin/systemctl enable registrator.service
vm123$ sudo /bin/systemctl start registrator.service
vm123$ sudo /bin/systemctl status registrator.service
```


Check:
```
vm1$ dig +short registry.service.consul
192.168.40.11
```


## HAProxy
```
vm123$ sudo yum -y install haproxy

vm123$ sudo tee /etc/haproxy/haproxy.cfg <<eof
global
    log 127.0.0.1 local0 notice
    chroot /var/lib/haproxy
    maxconn 2000
    user haproxy
    group haproxy

defaults
    log global
    mode http
    option httplog
    retries 3
    option redispatch
    timeout connect 5000ms
    timeout client 50000ms
    timeout server 50000ms

listen statslisten8080
    bind *:8080
    stats enable
    stats uri /haproxy?stats
    stats realm Private
    stats auth admin:admin
eof

vm123$ sudo /bin/systemctl enable haproxy.service
vm123$ sudo /bin/systemctl start haproxy.service
vm123$ sudo /bin/systemctl status haproxy.service
```


## Consul-template
```
vm1$23 sudo yum -y localinstall /vagrant/rpmbuild/centos/7/x86_64/RPMS/x86_64/consul-template-0.14.0-1.mecachis.centos7.x86_64.rpm

vm1$23 sudo /sbin/setsebool -P haproxy_connect_any on

vm123$ sudo tee /usr/local/etc/consul-template/templates/haproxy.ctmpl <<'eof'
global
    log 127.0.0.1 local0 notice
    chroot /var/lib/haproxy
    maxconn 2000
    user haproxy
    group haproxy

defaults
    log global
    mode http
    option httplog
    retries 3
    option redispatch
    timeout connect 5000ms
    timeout client 50000ms
    timeout server 50000ms

frontend frontend
    bind *:80
    stats enable
    stats uri /haproxy?stats
    stats realm Private
    stats auth admin:admin
{{- range $service := services }}
  {{- range $tag, $services := service $service.Name | byTag }}
    use_backend backend-{{ $tag }}.{{ $service.Name }}.abril if { hdr(Host) -i {{ $tag }}.{{ $service.Name }}.abril }
  {{- end }}
{{- end }}
    default_backend backend-default

backend backend-default
    errorfile 503 /etc/haproxy/503.html
{{- range $service := services }}
  {{- range $tag, $services := service $service.Name | byTag }}

backend backend-{{ $tag }}.{{ $service.Name }}.abril
    balance roundrobin
    option httpchk GET /status HTTP/1.1\r\nHost:\ localhost\r\nUser-Agent: haproxy\r\n\r\n
    option forwardfor
    {{- range $n, $service := $services }}
    server {{.Node}} {{.Address}}:{{.Port}} id {{ $n | add 1}} check
    {{- end }}
  {{- end }}
{{- end }}
eof
```

Note that the Golang run-time http server implementation would
fail unless the User-Agent header was present...


```
vm3$ sudo tee /usr/local/etc/consul-template/templates/503.ctmpl <<'eof'
HTTP/1.0 503 Service Unavailable
Cache-Control: no-cache
Connection: close
Content-Type: text/html

<html>
  <head>
    <title>Hello</title>
  </head>
  <body>
    <div>
      <h2>Hello</h2>
      <ul>
        {{- range $service := services }}
        {{- range $tag, $services := service $service.Name | byTag }}
        <li>
          <a href="http://{{ $tag }}.{{ $service.Name }}.abril/status">
            {{ $tag }}.{{ $service.Name }}.abril
          </a>
        </li>
        {{- end }}
        {{- end }}
      </ul>
    </div>
  </body>
</html>
eof


vm123$ sudo tee /usr/local/etc/consul-template/conf.d/config.hcl <<eof
consul = "localhost:8500"

template {
    source = "/usr/local/etc/consul-template/templates/haproxy.ctmpl"
    destination = "/etc/haproxy/haproxy.cfg"
    command = "/bin/systemctl reload haproxy.service"
}

template {
    source = "/usr/local/etc/consul-template/templates/503.ctmpl"
    destination = "/etc/haproxy/503.html"
    command = "/bin/systemctl reload haproxy.service"
}
eof

vm123$ sudo mkdir /etc/systemd/system/consul-template.service.d
vm123$ sudo tee /etc/systemd/system/consul-template.service.d/user.conf <<eof
[Service]
User=root
eof

vm123$ sudo /bin/systemctl reenable consul-template.service
vm123$ sudo /bin/systemctl start consul-template.service
vm123$ sudo /bin/systemctl status consul-template.service
```


Check:
```
vm123$ /bin/systemctl --failed
```


## Building and publishing microservices

Using the latest version of golang 1.6.2 as wasn't able to embed the
build version with CentOS' stock golang 1.4.2.
```
vm1$ sudo yum -y localinstall /vagrant/rpmbuild/centos/7/x86_64/RPMS/x86_64/golang-1.6.2-1.mecachis.centos7.x86_64.rpm

vm1$ cd /vagrant/images/date/
vm1$ rm -f build bin/date ; make build VERSION=1.0.0
vm1$ sudo docker tag cs/date:1.0.0 registry.service.consul:5000/cs/date:1.0.0
vm1$ sudo docker push registry.service.consul:5000/cs/date:1.0.0

vm1$ cd /vagrant/images/time/
vm1$ rm -f build bin/time ; make build VERSION=1.0.0
vm1$ sudo docker tag cs/time:1.0.0 registry.service.consul:5000/cs/time:1.0.0
vm1$ sudo docker push registry.service.consul:5000/cs/time:1.0.0

vm1$ cd /vagrant/images/web/
vm1$ rm -f build bin/web ; make build VERSION=1.0.0
vm1$ sudo docker tag cs/web:1.0.0 registry.service.consul:5000/cs/web:1.0.0
vm1$ sudo docker push registry.service.consul:5000/cs/web:1.0.0
```


## Pulling and running microservices
```
vm1$ cd /vagrant/dockercompose/date/
vm1$ VERSION=1.0.0 /usr/local/docker-compose/bin/docker-compose \
	-H tcp://vm1:3375 -p datea1b0c0 scale date=3

vm1$ cd /vagrant/dockercompose/time/
vm1$ VERSION=1.0.0 /usr/local/docker-compose/bin/docker-compose \
	-H tcp://vm1:3375 -p timea1b0c0 scale time=3

vm1$ cd /vagrant/dockercompose/web/
vm1$ VERSION=1.0.0 /usr/local/docker-compose/bin/docker-compose \
	-H tcp://vm1:3375 -p weba1b0c0 scale web=3
```

Note this will fail with '404 page not found' if you specify
a trailing slash to the -H argument, e.g. -H tcp://vm1:3375/


## Register service consumer endpoints
```
vm1$ curl -X PUT -d '{
  "Node": "1.date",
  "Address": "1.0.0.date.service.consul",
  "Service": {
    "Service": "date-1",
    "Port": 0
  }
}' http://127.0.0.1:8500/v1/catalog/register

vm1$ curl -X PUT -d '{
  "Node": "1.time",
  "Address": "1.0.0.time.service.consul",
  "Service": {
    "Service": "time-1",
    "Port": 0
  }
}' http://127.0.0.1:8500/v1/catalog/register
```


Check:
```
vm1$ cd /vagrant/dockercompose/web/
vm1$ VERSION=1.0.0 /usr/local/docker-compose/bin/docker-compose \
	-H tcp://vm1:3375 -p weba1b0c0 ps
vm1$ docker -H tcp://vm1:3375/ ps
vm1$ dig +short date-1.service.consul
vm1$ dig +short 1.0.0.date.service.consul in srv
vm1$ dig +short time-1.service.consul
vm1$ dig +short 1.0.0.time.service.consul in srv
vm1$ dig +short 1.0.0.web.service.consul in srv

vm1$ egrep '^(backend|    server)' /etc/haproxy/haproxy.cfg
backend backend-default
backend backend-1.0.0.date.abril
    server vm2 192.168.121.75:32769 id 1 check
    server vm2 192.168.121.75:32770 id 2 check
    server vm3 192.168.121.201:32770 id 3 check
backend backend-1.0.0.hostnamehttpserver.abril
    server vm2 192.168.121.75:32768 id 1 check
    server vm3 192.168.121.201:32769 id 2 check
    server vm3 192.168.121.201:32768 id 3 check
backend backend-1.0.0.time.abril
    server vm1 192.168.121.132:32768 id 1 check
    server vm2 192.168.121.75:32771 id 2 check
    server vm3 192.168.121.201:32771 id 3 check
backend backend-1.0.0.web.abril
    server vm1 192.168.121.132:32769 id 1 check
    server vm2 192.168.121.75:32772 id 2 check
    server vm3 192.168.121.201:32772 id 3 check


>> http://hello.abril/
>> http://1.0.0.date.abril/date
>> http://1.0.0.time.abril/time
>> http://1.0.0.web.abril/
>> http://1.0.0.web.abril/haproxy?stats

	- admin:admin


vm1$ curl http://1.0.0.web.abril/
5326ac774543 1.0.0:
20160513 - 373d2dc42fdb 1.0.0
17:48:26 - 47f33e7b4327 1.0.0
vm1$ curl http://1.0.0.web.abril/
985df125dd9a 1.0.0:
20160513 - c552c8ed9872 1.0.0
17:48:30 - 6f1831949114 1.0.0
vm1$ curl http://1.0.0.web.abril/
aab6585f0b06 1.0.0:
20160513 - 373d2dc42fdb 1.0.0
17:48:31 - a78a36c76a4f 1.0.0
```


## Rescaling
```
vm1$ cd /vagrant/dockercompose/date/
vm1$ VERSION=1.0.0 /usr/local/docker-compose/bin/docker-compose \
	-H tcp://vm1:3375 -p datea1b0c0 scale date=6
```

Note this will fail with '404 page not found' if you specify
a trailing slash to the -H argument, e.g. -H tcp://vm1:3375/


## Building and publishing new version of microservice
```
vm1$ cd /vagrant/images/date/
vm1$ rm -f build bin/date ; make build VERSION=1.0.1
vm1$ sudo docker tag cs/date:1.0.1 registry.service.consul:5000/cs/date:1.0.1
vm1$ sudo docker push registry.service.consul:5000/cs/date:1.0.1
```


## Pulling and running new version of microservice
```
vm1$ cd /vagrant/dockercompose/date/
vm1$ VERSION=1.0.1 /usr/local/docker-compose/bin/docker-compose \
	-H tcp://vm1:3375 -p datea1b0c1 scale date=3
```


## Register updated service consumer endpoint
```
vm1$ curl -X PUT -d '{
  "Node": "1.date",
  "Address": "1.0.1.date.service.consul",
  "Service": {
    "Service": "date-1",
    "Port": 0
  }
}' http://127.0.0.1:8500/v1/catalog/register
```


Check:
```
vm1$ cd /vagrant/dockercompose/date/
vm1$ VERSION=1.0.1 /usr/local/docker-compose/bin/docker-compose \
	-H tcp://vm1:3375 -p datea1b0c1 ps
vm1$ docker -H tcp://vm1:3375/ ps
vm1$ dig +short 1.0.0.date.service.consul in srv
vm1$ dig +short 1.0.1.date.service.consul in srv


>> http://1.0.0.date.abril/date
>> http://1.0.1.date.abril/date
>> http://1.0.0.web.abril/
>> http://1.0.0.web.abril/haproxy?stats

	- admin:admin


vm1$ curl http://1.0.0.web.abril/
5326ac774543 1.0.0:
20160513 - 373d2dc42fdb 1.0.1
17:48:26 - 47f33e7b4327 1.0.0
vm1$ curl http://1.0.0.web.abril/
985df125dd9a 1.0.0:
20160513 - c552c8ed9872 1.0.1
17:48:30 - 6f1831949114 1.0.0
vm1$ curl http://1.0.0.web.abril/
aab6585f0b06 1.0.0:
20160513 - 373d2dc42fdb 1.0.1
17:48:31 - a78a36c76a4f 1.0.0
```


## Tear down unused service implementation
```
vm1$ cd /vagrant/dockercompose/date/
vm1$ VERSION=1.0.1 /usr/local/docker-compose/bin/docker-compose \
	-H tcp://vm1:3375 -p datea1b0c0 down
```


## Deregister service consumer endpoints
```
vm1$ curl -X PUT -d '{
  "Node": "1.date"
}
' http://127.0.0.1:8500/v1/catalog/deregister

vm1$ curl -X PUT -d '{
  "Node": "1.time"
}
' http://127.0.0.1:8500/v1/catalog/deregister
```


# To do

- Upcoming version 1.12:
  - http://container-solutions.com/hail-new-docker-swarm/

- engine:
  - Enable tls.
    https://docs.docker.com/engine/security/https/

- swarm:
  - Test reschedule:on-node-failure behaviour more - doesn't seem to
    work fully - things like port mappings are lost when containers are
    restarted...

- images:
  - Improve content type handling.
  - Switch user id away from root.

- rpms:
  - Fix failed service on rpm removal.
  - Check Requires and BuildRequires working in rpms.

- consul:
  - Note warning:
    Service tag "1.0.0" will not be discoverable via DNS due to invalid characters. Valid characters include all alpha-numerics and dashes.
  - Enable access control on Consul database.

- Nomad:
  - http://sysadvent.blogspot.co.uk/2015/12/day-12-introduction-to-nomad.html


# Other notes

## Docker overlay network support
```
vm1$ sudo tee /etc/sysconfig/docker <<eof
OPTIONS="-H fd:// -H tcp://0.0.0.0:2375 --cluster-advertise 192.168.40.11:2375 --cluster-store consul://localhost:8500"
eof

vm2$ sudo tee /etc/sysconfig/docker <<eof
OPTIONS="-H fd:// -H tcp://0.0.0.0:2375 --cluster-advertise 192.168.40.12:2375 --cluster-store consul://localhost:8500"
eof

vm3$ sudo tee /etc/sysconfig/docker <<eof
OPTIONS="-H fd:// -H tcp://0.0.0.0:2375 --cluster-advertise 192.168.40.13:2375 --cluster-store consul://localhost:8500"
eof

vm123$ sudo /bin/systemctl restart docker.service
vm123$ sudo /bin/systemctl status docker.service
```


Check:
```
vm1$ curl -s http://localhost:8500/v1/kv/?recurse | python -mjson.tool

vm123$ sudo docker network ls

vm1$ sudo docker network create -d overlay hola

vm123$ sudo docker network ls
```


## Building and publishing hostnamehttpserver
```
vm1$ cd /vagrant/images/hostnamehttpserver/
vm1$ rm build ; make build VERSION=1.0.0
vm1$ sudo docker tag \
        cs/hostnamehttpserver:1.0.0 \
        registry.service.consul:5000/cs/hostnamehttpserver:1.0.0
vm1$ sudo docker push registry.service.consul:5000/cs/hostnamehttpserver:1.0.0
```


## Pulling and running hostnamehttpserver
```
vm1$ cd /vagrant/dockercompose/hostnamehttpserver/
vm1$ VERSION=1.0.0 /usr/local/docker-compose/bin/docker-compose \
	-H tcp://vm1:3375 -p hostnamehttpservera1b0c0 scale web=3
```

Note this will fail with '404 page not found' if you specify
a trailing slash to the -H argument, e.g. -H tcp://vm1:3375/


Check:
```
vm1$ cd /vagrant/dockercompose/hostnamehttpserver/
vm1$ VERSION=1.0.0 /usr/local/docker-compose/bin/docker-compose \
	-H tcp://vm1:3375 -p hostnamehttpservera1b0c0 ps
vm1$ docker -H tcp://vm1:3375/ ps
vm123$ dig +short 1.0.0.hostnamehttpserver.service.consul in srv

vm1$ egrep '^(backend|    server)' /etc/haproxy/haproxy.cfg
backend backend-default
backend backend-1.0.0.hostnamehttpserver.abril
    server vm2 192.168.121.75:32768 id 1 check
    server vm3 192.168.121.201:32769 id 2 check
    server vm3 192.168.121.201:32768 id 3 check


>> http://hello.abril/
>> http://1.0.0.hostnamehttpserver.abril/
>> http://1.0.0.hostnamehttpserver.abril/haproxy?stats

	- admin:admin
```


## docker import vs. CentOS
```
vm1$ sudo yum grouplist | less
vm1$ sudo yum grouplist hidden | less

vm1$ sudo mkdir /tmp/cs
vm1$ cd /tmp/cs

vm1$ sudo yum -y install yum-utils
vm1$ sudo yumdownloader centos-release

vm1$ mkdir /tmp/cs1
vm1$ sudo rpm --root /tmp/cs1 --initdb
vm1$ sudo rpm --root /tmp/cs1 \
	-ivh /tmp/cs/centos-release-7-2.1511.el7.centos.2.10.x86_64.rpm

vm1$ echo n | sudo yum --installroot /tmp/cs1 groupinstall Core
.
.
Installed size: 580 M

vm1$ echo n | sudo yum --installroot /tmp/cs1 groupinstall 'Minimal Install'
.
.
Installed size: 580 M

	- Looks like Core and Minimal Install are the same.


vm1$ sudo yum -y --installroot /tmp/cs1 install bash coreutils yum
.
.
Installed size: 245 M


vm1$ sudo du -sh /tmp/cs1
338M	/tmp/cs1

vm1$ sudo yum --installroot /tmp/cs1 clean all

vm1$ sudo du -sh /tmp/cs1
276M	/tmp/cs1

vm1$ sudo tar -cvf - -C /tmp/cs1 . | \
	sudo docker import \
		--change 'CMD /bin/bash' \
		-m 'Hello' \
		- abril/abrilcentos:7

vm1$ sudo docker run -i -t --rm abril/abrilcentos:7


- Note the image sizes:

vm1$ sudo docker images abril/abrilcentos:7
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
abril/abrilcentos   7                   35b9eb0a4039        11 minutes ago      264.9 MB

vm1$ sudo docker images docker.io/centos:7
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
docker.io/centos    7                   a65193109361        4 days ago          196.7 MB
```


## registry housekeeping

Very scarce documentation but it looks like it works...

See:
- https://docs.docker.com/registry/spec/api/
- https://docs.docker.com/registry/garbage-collection/

It looks like:
- A repository is a collection of tags.
- A tag is a reference to an image.
- If no references to an image exist then it can be garbage collected.
```
vm1$ cd /vagrant/dockercompose/registry/
vm1$ /usr/local/docker-compose/bin/docker-compose -H tcp://vm1:3375 down

vm1$ sudo docker run -d -i -t \
	--name registry.docker --hostname registry.docker \
	-p 5000:5000 \
	-v /vagrant/ssl:/certs \
	-e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/registry.service.consul.crt \
	-e REGISTRY_HTTP_TLS_KEY=/certs/registry.service.consul.key \
	-e REGISTRY_STORAGE_DELETE_ENABLED=True \
	-l SERVICE_NAME=registry \
	registry:2


vm1$ sudo docker pull centos:5
vm1$ sudo docker tag centos:5 registry.service.consul:5000/abril/centos:5
vm1$ sudo docker push registry.service.consul:5000/abril/centos:5

vm1$ sudo docker pull centos:6
vm1$ sudo docker tag centos:6 registry.service.consul:5000/abril/centos:6
vm1$ sudo docker push registry.service.consul:5000/abril/centos:6

vm1$ sudo docker pull centos:7
vm1$ sudo docker tag centos:7 registry.service.consul:5000/abril/centos:7
vm1$ sudo docker push registry.service.consul:5000/abril/centos:7

vm1$ sudo docker pull nginx:latest
vm1$ sudo docker tag nginx:latest registry.service.consul:5000/abril/nginx:latest
vm1$ sudo docker push registry.service.consul:5000/abril/nginx:latest


vm1$ curl -k https://registry.service.consul:5000/v2/_catalog
{"repositories":["abril/centos","abril/nginx"]}

vm1$ curl -k https://registry.service.consul:5000/v2/abril/centos/tags/list
{"name":"abril/centos","tags":["5","7","6"]}

vm1$ curl -k https://registry.service.consul:5000/v2/abril/nginx/tags/list
{"name":"abril/nginx","tags":["latest"]}


vm1$ curl -s -i -k \
	-H 'Accept: application/vnd.docker.distribution.manifest.v2+json' \
	https://registry.service.consul:5000/v2/abril/centos/manifests/6 | \
	grep 'Docker-Content-Digest:'
Docker-Content-Digest: sha256:15951ff5ee11d4a7008a0e71afd61f52f22b4f95758a627a18d18dbc39012962

vm1$ curl -i -X DELETE -k https://registry.service.consul:5000/v2/abril/centos/manifests/sha256:15951ff5ee11d4a7008a0e71afd61f52f22b4f95758a627a18d18dbc39012962


vm1$ curl -s -i -k \
	-H 'Accept: application/vnd.docker.distribution.manifest.v2+json' \
	https://registry.service.consul:5000/v2/abril/nginx/manifests/latest | \
	grep 'Docker-Content-Digest:'
Docker-Content-Digest: sha256:af1103d3bd66af998db61c8862c56f02f76dfb556eb84ef58b2d699fbee62f0e

vm1$ curl -i -X DELETE -k https://registry.service.consul:5000/v2/abril/nginx/manifests/sha256:af1103d3bd66af998db61c8862c56f02f76dfb556eb84ef58b2d699fbee62f0e


vm1$ sudo docker exec registry.docker du -sh /var/lib/registry/
285M	/var/lib/registry/

vm1$ sudo docker exec -i -t registry.docker \
	/bin/registry garbage-collect /etc/docker/registry/config.yml
INFO[0000] Deleting blob: /docker/registry/v2/blobs/sha256/bc/bcd41daec8cc835577e660ddef75e655f6ff3742bad92c9c498d8eba097b512a  go.version=go1.6.2 instance.id=eb9f5869-b318-4236-9312-0ed4df2111f5
INFO[0000] Deleting blob: /docker/registry/v2/blobs/sha256/0d/0d409d33b27e47423b049f7f863faa08655a8c901749c2b25b93ca67d01a470d  go.version=go1.6.2 instance.id=eb9f5869-b318-4236-9312-0ed4df2111f5
INFO[0000] Deleting blob: /docker/registry/v2/blobs/sha256/15/15951ff5ee11d4a7008a0e71afd61f52f22b4f95758a627a18d18dbc39012962  go.version=go1.6.2 instance.id=eb9f5869-b318-4236-9312-0ed4df2111f5
INFO[0000] Deleting blob: /docker/registry/v2/blobs/sha256/51/51d229e136d0acdb3db7fae7e02d07bcb9b6ffb9bcaac88cc26aaf0be8bea045  go.version=go1.6.2 instance.id=eb9f5869-b318-4236-9312-0ed4df2111f5
INFO[0000] Deleting blob: /docker/registry/v2/blobs/sha256/51/51f5c6a04d83efd2d45c5fd59537218924bc46705e3de6ffc8bc07b51481610b  go.version=go1.6.2 instance.id=eb9f5869-b318-4236-9312-0ed4df2111f5
INFO[0000] Deleting blob: /docker/registry/v2/blobs/sha256/66/66b3168580025d6e9a4ee8353110d896a757ef4dd126eb95c03615ece891c250  go.version=go1.6.2 instance.id=eb9f5869-b318-4236-9312-0ed4df2111f5
INFO[0000] Deleting blob: /docker/registry/v2/blobs/sha256/6a/6a77ab6655b90cf85a0b353a0c4f631b3dcd5db251ce0da3a68357c4ee8cb45b  go.version=go1.6.2 instance.id=eb9f5869-b318-4236-9312-0ed4df2111f5
INFO[0000] Deleting blob: /docker/registry/v2/blobs/sha256/af/af1103d3bd66af998db61c8862c56f02f76dfb556eb84ef58b2d699fbee62f0e  go.version=go1.6.2 instance.id=eb9f5869-b318-4236-9312-0ed4df2111f5

vm1$ sudo docker exec registry.docker du -sh /var/lib/registry/
151M	/var/lib/registry/


vm1$ curl -k https://registry.service.consul:5000/v2/_catalog
{"repositories":["abril/centos","abril/nginx"]}

vm1$ curl -k https://registry.service.consul:5000/v2/abril/centos/tags/list
{"name":"abril/centos","tags":["5","7"]}

vm1$ curl -k https://registry.service.consul:5000/v2/abril/nginx/tags/list
{"name":"abril/nginx","tags":null}


vm2$ sudo docker pull registry.service.consul:5000/abril/centos:5

	- Works - cool.

vm2$ sudo docker pull registry.service.consul:5000/abril/centos:6

	- Doesn't work - cool.

vm2$ sudo docker pull registry.service.consul:5000/abril/centos:7

	- Works - cool.

vm2$ sudo docker pull registry.service.consul:5000/abril/nginx:latest

	- Doesn't work - cool.
```
